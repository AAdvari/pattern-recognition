{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Part 1: Gradient Descent + Example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5535ef6a2317fe7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<div style=\"text-align: right; direction: rtl;\">\n",
    "\n",
    "### الگوریتم گرادیان کاهشی یک الگوریتم بهینه‌سازی‌ است که برای بهینه‌سازی توابع مشتق‌پذیر استفاده می‌شود\n",
    "### این الگوریتم معمولا در هر مرحله در جهت معکوس گرادیان تابع هدف حرکت می‌کند تا به نقطه‌ای برسد که گرادیان تابع هدف در آن نقطه صفر شود\n",
    "### این الگوریتم برای بهینه‌سازی توابع مشتق‌پذیر استفاده می‌شود و می‌تواند بهینه‌سازی توابع غیرخطی را انجام دهد\n",
    "### در یادگیری‌ماشین این الگوریتم اصولا برای بهینه‌سازی توابع هزینه (که همان اختلاف بین خروجی مدل و خروجی واقعی است) استفاده می‌شود\n",
    "### فرمول گرادیان کاهشی به صورت زیر است\n",
    "### $w = w - \\alpha \\nabla Q(w)$\n",
    "### که در این فرمول $w$ وزن‌های مدل، $\\alpha$ نرخ یادگیری و $\\nabla Q(w)$ گرادیان تابع هزینه است\n",
    "### در این قسمت یک مثال ساده از الگوریتم گرادیان کاهشی ارائه شده است\n",
    "### فرض کنید یک مدل خطی به‌صورت زیر داریم و می‌خواهیم تتا را به‌روزرسانی کنیم به‌گونه‌ای که خط مدل بهترین تطابق را با داده‌ها داشته باشد\n",
    "### به‌عبارتی دیگر می‌خواهیم تتا را به‌گونه‌ای به‌روزرسانی کنیم که مقدار تابع هزینه کمینه شود\n",
    "### $y = \\theta x $\n",
    "### فرض می‌کنیم حدس اولیه ما برای تتا برابر ۳ بوده و نقاط داده‌ای ما به‌صورت زیر است \n",
    "### $X = [1, 2, 3, 4]$\n",
    "### $Y = [2, 4, 6, 8]$\n",
    "### در این مثال ما می‌خواهیم تتا را به‌روزرسانی کنیم به‌گونه‌ای که خطی که از این تتا به‌دست می‌آید بهترین تطابق را با داده‌ها داشته باشد\n",
    "### برای این‌کار ابتدا تابع هزینه را تعریف می‌کنیم\n",
    "### $Q = \\frac{1}{2n} \\sum_{i=1}^{n} (y_i - \\theta x_i)^2$\n",
    "### سپس گرادیان تابع هزینه را محاسبه می‌کنیم\n",
    "### $\\nabla Q = \\frac{-1}{n} \\sum_{i=1}^{n} (y_i - \\theta x_i) x_i$\n",
    "### در نهایت تتا را به‌روزرسانی می‌کنیم\n",
    "### $\\theta = \\theta - \\alpha \\nabla Q$\n",
    "### در این مثال مقدار $\\alpha$ را برابر 0.01 در نظر می‌گیریم و یکبار این کار را تکرار می‌کنیم\n",
    "### میدانیم در عمل تعداد تکرار ها بیش‌تر است \n",
    "### در این مثال مقدار گرادیان برابر\n",
    "### $\\nabla Q = \\frac{-1}{4} \\sum_{i=1}^{4} (y_i - \\theta x_i) x_i = \\frac{-1}{4} \\sum_{i=1}^{4} (y_i - 3 x_i) x_i$\n",
    "### $= \\frac{-1}{4} \\sum_{i=1}^{4} (y_i x_i - 3 x_i^2) = \\frac{-1}{4} \\sum_{i=1}^{4} (2 x_i^2 - 3 x_i^2)$\n",
    "### $= \\frac{-1}{4} \\sum_{i=1}^{4} - x_i^2 = \\frac{1}{4} \\sum_{i=1}^{4} x_i^2$\n",
    "### $= \\frac{1}{4} (1 + 4 + 9 + 16) = \\frac{1}{4} \\times 30 = 7.5$ \n",
    "### پس مقدار جدید تتا برابر است با\n",
    "### $\\theta = 3 - 0.01 \\times 7.5 = 3 - 0.075 = 2.925$\n",
    "### در این‌جا مقدار جدید تتا برابر 2.925 است\n",
    "### یعنی به مقدار بهینه نزدیک‌تر شدیم\n",
    "### با تکرار این کار مقدار تتا به مقدار بهینه 2 نزدیک‌تر می‌شود\n",
    "\n",
    "</div>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "914a71773220475c"
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-24T23:02:11.504318Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reading Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "327f60fb1ded5dc"
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/1.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-24T23:02:11.724283Z",
     "start_time": "2024-10-24T23:02:11.697300Z"
    }
   },
   "id": "906dee57a1d65c95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Polynomial Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d2fca9a3e4a5549"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: right; direction: rtl; line-height:3;\">\n",
    "\n",
    "\n",
    "####  مدل رگرسیون چندجمله‌ای\n",
    "در این بخش می‌خواهیم یک مدل رگرسیون چندجمله‌ای ارائه دهیم که بتواند داده‌های غیرخطی را نیز تخمین بزند\n",
    "برای این‌کار ابتدا یک مدل خطی ارائه می‌دهیم که به‌صورت زیر است\n",
    "\n",
    "$y = w_0 + w_1 x_1 + w_2 x_2 + ... + w_n x_n$\n",
    "\n",
    "سپس این مدل را به‌گونه‌ای تغییر می‌دهیم که بتواند داده‌های غیرخطی را نیز تخمین بزند\n",
    "برای این‌کار ابتدا تمامی توان‌های ممکن برای هر یک از ویژگی‌ها را محاسبه می‌کنیم\n",
    "سپس تمامی ترکیب‌های ممکن از این توان‌ها را محاسبه می‌کنیم می‌توانیم این کار را به‌صورت بازگشتی انجام دهیم و تمامی ترکیب‌های ممکن از توان‌ها را به‌دست آوریم می‌دانیم اگر تعداد ویژگی‌ها $n$ باشد و مجموع توان‌ها $m$ باشد تعداد ترکیب‌های ممکن یکتا از توان‌ها برابر است با (مسئله میله‌ها و ستاره‌ها)\n",
    " \n",
    "\n",
    "$\\binom{n+m-1}{m - 1}$\n",
    "\n",
    "سپس ویژگی‌های جدیدی که از ترکیب‌های مختلف توان‌ها به‌دست می‌آید را به‌عنوان ویژگی‌های جدید به مدل خطی اضافه می‌کنیم\n",
    "در نهایت مدل خطی جدیدی که از این‌جا به‌دست می‌آید مدل رگرسیون چندجمله‌ای است\n",
    "\n",
    "به‌طور مثال اگر تعداد ویژگی‌ها ۲ باشد و می‌خواهیم توان‌ها تا ۳ را در نظر بگیریم تعداد ترکیب‌های ممکن برابر است با (یک واحد به تعداد ویژگی‌ها اضافه می‌کنیم برای بایاس)\n",
    "\n",
    "$\\binom{3+3-1}{3 - 1} = \\binom{5}{2} = 10$\n",
    "\n",
    "و ترکیب‌های ممکن از توان‌ها به‌صورت زیر است\n",
    "\n",
    "$[0, 0], [0, 1], [0, 2], [0, 3], [1, 0], [1, 1], [1, 2], [2, 0], [2, 1], [3, 0]$\n",
    "\n",
    "و ویژگی‌های جدیدی که به‌دست می‌آید به‌صورت زیر است\n",
    "\n",
    "$[1, x_1, x_2, x_1^2, x_1 x_2, x_2^2, x_1^3, x_1^2 x_2, x_1 x_2^2, x_2^3]$\n",
    "\n",
    "\n",
    "#### مدل رگرسیون خطی\n",
    "در این مدل از الگوریتم گرادیان کاهشی برای بهینه‌سازی استفاده می‌کنیم و می‌توانیم مدل رگرسیون خطی را به‌صورت زیر ارائه دهیم\n",
    "\n",
    "$y = w_0 + w_1 x_1 + w_2 x_2 + ... + w_n x_n$\n",
    "\n",
    "این مدل را می‌توان به‌صورت ماتریسی زیر نوشت\n",
    "\n",
    "$\\hat{y} = X w$\n",
    "\n",
    "که در این‌جا $X$ ماتریس ویژگی‌ها و $w$ وزن‌های مدل است\n",
    "\n",
    "خطای مدل را می‌توان به‌صورت زیر نوشت\n",
    "\n",
    "$ e = X w - y $\n",
    "\n",
    "در اینجا $e$ خطای مدل و $y$ خروجی واقعی است\n",
    "\n",
    "تابع هزینه را به‌صورت ماتریسی می‌توان به‌صورت زیر نوشت\n",
    "\n",
    "$Q = \\frac{1}{2n} e^T e$\n",
    "\n",
    "که در این‌جا $n$ تعداد نمونه‌ها است\n",
    "\n",
    "گرادیان تابع هزینه را می‌توان به‌صورت زیر نوشت\n",
    "\n",
    "$\\nabla Q = \\frac{1}{n} X^T e$\n",
    "\n",
    "بدین‌ترتیب وزن‌هارا به‌صورت زیر به‌روزرسانی می‌کنیم \n",
    "\n",
    "$w = w - \\alpha \\nabla Q$\n",
    "\n",
    "که در این‌جا $\\alpha$ نرخ یادگیری است\n",
    "از رگولاریزیشن $l_1$ برای جلوگیری از بیش‌برازش استفاده می‌کنیم که به‌صورت زیر است\n",
    "\n",
    "$w = w - \\alpha \\nabla Q + \\lambda \\text{sign}(w)$\n",
    "\n",
    "که در این‌جا $\\lambda$ ضریب رگولاریزیشن است\n",
    "\n",
    "در نهایت مدل را به‌صورت زیر به‌روزرسانی می‌کنیم\n",
    "\n",
    "$w = w - \\alpha \\nabla Q + \\lambda \\text{sign}(w)$\n",
    "\n",
    "با تکرار این کار مدل بهینه می‌شود\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f252ca95a2a14f76"
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.array, epochs=100, learning_rate=0.01, lamb=0.01, gd = True):\n",
    "        rows, cols = X.shape\n",
    "        if not gd:\n",
    "            self.w = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "        else:\n",
    "            self.w = np.zeros(cols)\n",
    "            for _ in tqdm.tqdm(range(epochs)):\n",
    "                predicts = X @ self.w\n",
    "                errors = (predicts - y)\n",
    "                reg = lamb * np.sign(self.w)\n",
    "                reg[0] = 0\n",
    "                gradient = X.T @ errors / rows + reg\n",
    "                update_term = learning_rate  *  gradient\n",
    "                self.w -= update_term\n",
    "                \n",
    "            \n",
    "        \n",
    "    def predict(self, X: np.ndarray):\n",
    "        return X @ self.w\n",
    "\n",
    "    def score(self, X: np.ndarray, y: np.array):\n",
    "        y_pred = self.predict(X)\n",
    "        return  1 - ((y - y_pred)**2).sum() / ((y - y.mean())**2).sum()\n",
    "\n",
    "\n",
    "class PolynomialRegression: \n",
    "    def __init__(self, degree=2, epochs = 100):\n",
    "        self.degree = degree\n",
    "        self.epochs = epochs\n",
    "        self.powers = None\n",
    "        self.lr = MyLinearRegression()\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.array, epochs=100, learning_rate=0.01, gd = True):\n",
    "        X = self.add_bias(X)\n",
    "        self.powers = self.get_power_combinations(X.shape[1], self.degree)\n",
    "        X = self.get_pr_features(X, self.powers)\n",
    "        self.lr.fit(X, y, epochs=epochs, learning_rate=learning_rate, gd=gd)\n",
    "        \n",
    "    def score(self, X: np.ndarray, y: np.array):\n",
    "        X = self.add_bias(X)\n",
    "        X = self.get_pr_features(X, self.powers)\n",
    "        return self.lr.score(X, y)\n",
    "    \n",
    "    \n",
    "    def predict(self, X: np.ndarray):\n",
    "        X = self.add_bias(X)\n",
    "        X = self.get_pr_features(X, self.powers)\n",
    "        return X @ self.lr.w\n",
    "        \n",
    "    def add_bias(self, X: np.ndarray): \n",
    "        return np.column_stack((np.ones(X.shape[0]) , X))\n",
    "        \n",
    "    \n",
    "    def get_pr_features(self, X: np.ndarray, powers: np.ndarray = None):\n",
    "        if powers is None:\n",
    "            powers = self.get_power_combinations(X.shape[1], self.degree)\n",
    "        return np.prod(np.power(X[:, np.newaxis], powers), axis=-1)\n",
    "\n",
    "\n",
    "    def get_power_combinations(self, n: int, m: int): \n",
    "        if n == 1:\n",
    "            return [[m]]\n",
    "        if m == 0:\n",
    "            return [[0 for _ in range(n)]]\n",
    "        sols = []\n",
    "        for i in range(m+1):\n",
    "            for sol in self.get_power_combinations(n-1, m - i):\n",
    "                sols.append(\n",
    "                    [i] + sol\n",
    "                )\n",
    "        return sols"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:04:36.827078Z",
     "start_time": "2024-10-25T00:04:36.789310Z"
    }
   },
   "id": "ab60fddebbc74275"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: right; direction: rtl; line-height:3;\">\n",
    "\n",
    "#### توابع زیر را برای جداکردن داده‌ها به دو بخش آموزش و تست ارائه داده‌ایم\n",
    "\n",
    "\n",
    "</div> "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa7ad044620c35df"
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [],
   "source": [
    "\n",
    "def train_test_split_manual(df, test_size=0.2, random_state=None, shuffle=True):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = int(len(df) * test_size)\n",
    "\n",
    "    train_df = df.iloc[:-test_size].reset_index(drop=True)\n",
    "    test_df = df.iloc[-test_size:].reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:04:37.482631Z",
     "start_time": "2024-10-25T00:04:37.479271Z"
    }
   },
   "id": "8937193d21cbff92"
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES = [\n",
    "    'Rooms', 'Distance', 'Bedroom2', 'Postcode', 'Bathroom', 'Car',\n",
    "    'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude', 'Propertycount',\n",
    "]\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'Suburb', 'Type', 'Method', 'SellerG', 'CouncilArea', 'Regionname', 'Date'\n",
    "]\n",
    "PREDICT = 'Price'\n",
    "\n",
    "train, test = train_test_split_manual(df, test_size=.2, random_state=40, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:04:37.813505Z",
     "start_time": "2024-10-25T00:04:37.802563Z"
    }
   },
   "id": "fb4c46b215f1f3fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: right; direction: rtl; line-height:3;\">\n",
    "\n",
    "#### توابع زیر را برای نرمال‌سازی و استاندارد‌سازی داده‌ها ارائه داده‌ایم\n",
    "\n",
    "#### نرمال‌سازی داده‌ها به‌صورت زیر است\n",
    "\n",
    "$X_{\\text{norm}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}$\n",
    "\n",
    "\n",
    "#### استاندارد‌سازی داده‌ها به‌صورت زیر است\n",
    "\n",
    "$X_{\\text{std}} = \\frac{X - \\mu}{\\sigma}$\n",
    "\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "363c2bf55f4d870c"
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "def normalize_df(matrix: np.ndarray):\n",
    "    return (matrix - matrix.min(axis=0)) / (matrix.max(axis=0) - matrix.min(axis=0))\n",
    "def standardize_df(matrix: np.ndarray):\n",
    "    return (matrix - matrix.mean(axis=0)) / matrix.std(axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:04:38.169113Z",
     "start_time": "2024-10-25T00:04:38.165189Z"
    }
   },
   "id": "a920eece643ee552"
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T16:34:10.748232Z",
     "start_time": "2024-10-25T16:34:10.745503Z"
    }
   },
   "id": "18094c50c5336c67"
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 31536.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "np.float64(0.02286829088943343)"
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr1 = PolynomialRegression(degree=1)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "train_numeric = imp.fit_transform(train[NUMERICAL_FEATURES])\n",
    "\n",
    "train_numeric = normalize_df(train_numeric)\n",
    "\n",
    "y = train[PREDICT].values\n",
    "pr1.fit(train_numeric, y, epochs=100, learning_rate=.01, gd=True)\n",
    "\n",
    "\n",
    "test_numeric = imp.fit_transform(test[NUMERICAL_FEATURES])\n",
    "test_numeric = normalize_df(test_numeric)\n",
    "\n",
    "y_test = test[PREDICT].values\n",
    "pr1.score(test_numeric, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T16:34:19.288257Z",
     "start_time": "2024-10-25T16:34:19.247565Z"
    }
   },
   "id": "ffcb8b60fca486b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5f48f174d2bb19d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
