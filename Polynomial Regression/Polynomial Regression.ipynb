{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1\n",
    "### "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e64275130bfc4c2"
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-24T23:02:11.504318Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/1.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-24T23:02:11.724283Z",
     "start_time": "2024-10-24T23:02:11.697300Z"
    }
   },
   "id": "906dee57a1d65c95"
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.array, epochs=100, learning_rate=0.01, lamb=0.1, gd = True):\n",
    "        rows, cols = X.shape\n",
    "        if not gd:\n",
    "            self.w = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "        else:\n",
    "            self.w = np.zeros(cols)\n",
    "            for _ in tqdm.tqdm(range(epochs)):\n",
    "                predicts = X @ self.w\n",
    "                errors = (predicts - y)\n",
    "                reg = lamb * np.sign(self.w)\n",
    "                reg[0] = 0\n",
    "                gradient = X.T @ errors / rows + reg\n",
    "                update_term = learning_rate  *  gradient\n",
    "                self.w -= update_term\n",
    "                \n",
    "            \n",
    "        \n",
    "    def predict(self, X: np.ndarray):\n",
    "        return X @ self.w\n",
    "\n",
    "    def score(self, X: np.ndarray, y: np.array):\n",
    "        y_pred = self.predict(X)\n",
    "        return  1 - ((y - y_pred)**2).sum() / ((y - y.mean())**2).sum()\n",
    "\n",
    "\n",
    "class PolynomialRegression: \n",
    "    def __init__(self, degree=2, epochs = 100):\n",
    "        self.degree = degree\n",
    "        self.epochs = epochs\n",
    "        self.powers = None\n",
    "        self.lr = MyLinearRegression()\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.array, epochs=100, learning_rate=0.01, gd = True):\n",
    "        X = self.add_bias(X)\n",
    "        self.powers = self.get_power_combinations(X.shape[1], self.degree)\n",
    "        X = self.get_pr_features(X, self.powers)\n",
    "        self.lr.fit(X, y, epochs=epochs, learning_rate=learning_rate, gd=gd)\n",
    "        \n",
    "    def score(self, X: np.ndarray, y: np.array):\n",
    "        X = self.add_bias(X)\n",
    "        X = self.get_pr_features(X, self.powers)\n",
    "        return self.lr.score(X, y)\n",
    "    \n",
    "    \n",
    "    def predict(self, X: np.ndarray):\n",
    "        X = self.add_bias(X)\n",
    "        X = self.get_pr_features(X, self.powers)\n",
    "        return X @ self.lr.w\n",
    "        \n",
    "    def add_bias(self, X: np.ndarray): \n",
    "        return np.column_stack((np.ones(X.shape[0]) , X))\n",
    "        \n",
    "    \n",
    "    def get_pr_features(self, X: np.ndarray, powers: np.ndarray = None):\n",
    "        if powers is None:\n",
    "            powers = self.get_power_combinations(X.shape[1], self.degree)\n",
    "        return np.prod(np.power(X[:, np.newaxis], powers), axis=-1)\n",
    "\n",
    "\n",
    "    def get_power_combinations(self, n: int, m: int): \n",
    "        if n == 1:\n",
    "            return [[m]]\n",
    "        if m == 0:\n",
    "            return [[0 for _ in range(n)]]\n",
    "        sols = []\n",
    "        for i in range(m+1):\n",
    "            for sol in self.get_power_combinations(n-1, m - i):\n",
    "                sols.append(\n",
    "                    [i] + sol\n",
    "                )\n",
    "        return sols"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:04:36.827078Z",
     "start_time": "2024-10-25T00:04:36.789310Z"
    }
   },
   "id": "ab60fddebbc74275"
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [],
   "source": [
    "def train_test_split_manual(df, test_size=0.2, random_state=None, shuffle=True):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = int(len(df) * test_size)\n",
    "\n",
    "    train_df = df.iloc[:-test_size].reset_index(drop=True)\n",
    "    test_df = df.iloc[-test_size:].reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:04:37.482631Z",
     "start_time": "2024-10-25T00:04:37.479271Z"
    }
   },
   "id": "8937193d21cbff92"
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES = [\n",
    "    'Rooms', 'Distance', 'Bedroom2', 'Postcode', 'Bathroom', 'Car',\n",
    "    'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude', 'Propertycount',\n",
    "]\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'Suburb', 'Type', 'Method', 'SellerG', 'CouncilArea', 'Regionname', 'Date'\n",
    "]\n",
    "PREDICT = 'Price'\n",
    "\n",
    "train, test = train_test_split_manual(df, test_size=.2, random_state=40, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:04:37.813505Z",
     "start_time": "2024-10-25T00:04:37.802563Z"
    }
   },
   "id": "fb4c46b215f1f3fc"
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "def normalize_df(matrix: np.ndarray):\n",
    "    return (matrix - matrix.min(axis=0)) / (matrix.max(axis=0) - matrix.min(axis=0))\n",
    "def standardize_df(matrix: np.ndarray):\n",
    "    return (matrix - matrix.mean(axis=0)) / matrix.std(axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:04:38.169113Z",
     "start_time": "2024-10-25T00:04:38.165189Z"
    }
   },
   "id": "a920eece643ee552"
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import SGDRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:04:38.516926Z",
     "start_time": "2024-10-25T00:04:38.512747Z"
    }
   },
   "id": "18094c50c5336c67"
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "data": {
      "text/plain": "0.46632168560846643"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr2 = PolynomialFeatures(degree=3)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "gdr = SGDRegressor(\n",
    "    loss='squared_error', \n",
    "    # penalty='l2', \n",
    "    # alpha=0.01, \n",
    "    # l1_ratio=0.15, \n",
    "    # fit_intercept=True, \n",
    "    max_iter=100, \n",
    "    # tol=0.001, \n",
    "    # shuffle=False, \n",
    "    # verbose=0, \n",
    "    # epsilon=0.1, \n",
    "    # random_state=None, \n",
    "    learning_rate='constant', \n",
    "    # eta0=0.01, \n",
    "    # power_t=0.25, \n",
    "    # early_stopping=False, \n",
    "    # validation_fraction=0.1, \n",
    "    # n_iter_no_change=5, \n",
    "    # warm_start=False, \n",
    "    # average=False\n",
    ")\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "train_numeric = imp.fit_transform(train[NUMERICAL_FEATURES])\n",
    "\n",
    "train_numeric = normalize_df(train_numeric)\n",
    "# train_numeric = standardize_df(train_numeric)\n",
    "\n",
    "train_numeric = pr2.fit_transform(train_numeric)\n",
    "y = train[PREDICT].values\n",
    "gdr.fit(train_numeric, y)\n",
    "\n",
    "\n",
    "test_numeric = imp.fit_transform(test[NUMERICAL_FEATURES])\n",
    "\n",
    "test_numeric = normalize_df(test_numeric)\n",
    "# test_numeric = standardize_df(test_numeric)\n",
    "\n",
    "test_numeric = pr2.fit_transform(test_numeric)\n",
    "\n",
    "y_test = test[PREDICT].values\n",
    "gdr.score(test_numeric, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:04:39.388738Z",
     "start_time": "2024-10-25T00:04:38.788384Z"
    }
   },
   "id": "9e1b1322e30da67b"
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 92.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "np.float64(nan)"
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr1 = PolynomialRegression(degree=4)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "train_numeric = imp.fit_transform(train[NUMERICAL_FEATURES])\n",
    "\n",
    "# train_numeric = normalize_df(train_numeric)\n",
    "train_numeric = standardize_df(train_numeric)\n",
    "\n",
    "y = train[PREDICT].values\n",
    "pr1.fit(train_numeric, y, epochs=100, learning_rate=.01, gd=True)\n",
    "\n",
    "\n",
    "test_numeric = imp.fit_transform(test[NUMERICAL_FEATURES])\n",
    "\n",
    "# test_numeric = normalize_df(test_numeric)\n",
    "test_numeric = standardize_df(test_numeric)\n",
    "\n",
    "y_test = test[PREDICT].values\n",
    "pr1.score(test_numeric, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:08:14.941049Z",
     "start_time": "2024-10-25T00:08:11.693052Z"
    }
   },
   "id": "ffcb8b60fca486b9"
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.0000000e+00,  1.7200000e+01,  2.0000000e+00, ...,\n        -3.7820470e+01,  1.4519421e+02,  6.8710000e+03],\n       [ 4.0000000e+00,  9.7000000e+00,  3.0000000e+00, ...,\n        -3.7736700e+01,  1.4492040e+02,  3.2840000e+03],\n       [ 3.0000000e+00,  1.0700000e+01,  3.0000000e+00, ...,\n        -3.7918500e+01,  1.4501380e+02,  6.9380000e+03],\n       ...,\n       [ 4.0000000e+00,  3.4000000e+00,  4.0000000e+00, ...,\n        -3.7784740e+01,  1.4493220e+02,  3.5930000e+03],\n       [ 4.0000000e+00,  8.9000000e+00,  4.0000000e+00, ...,\n        -3.7732260e+01,  1.4509855e+02,  2.6980000e+03],\n       [ 3.0000000e+00,  2.1300000e+01,  3.0000000e+00, ...,\n        -3.7827070e+01,  1.4522914e+02,  3.7940000e+03]])"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.fit_transform(train[NUMERICAL_FEATURES])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:07:34.578166Z",
     "start_time": "2024-10-25T00:07:34.566977Z"
    }
   },
   "id": "b42df9b631134bc3"
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.97763257,  1.20141904, -0.94131955, ..., -0.14284488,\n         1.90989459, -0.12931496],\n       [ 1.1276202 , -0.07171123,  0.09732514, ...,  0.91664815,\n        -0.71053867, -0.94735935],\n       [ 0.07499382,  0.09803947,  0.09732514, ..., -1.38269329,\n         0.18332374, -0.11403507],\n       ...,\n       [ 1.1276202 , -1.14114066,  1.13596982, ...,  0.30905539,\n        -0.59760959, -0.87688939],\n       [ 1.1276202 , -0.2075118 ,  1.13596982, ...,  0.97280368,\n         0.99440339, -1.08100139],\n       [ 0.07499382,  1.89739692,  0.09732514, ..., -0.22631932,\n         2.24418381, -0.83104972]])"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize_df(imp.fit_transform(train[NUMERICAL_FEATURES]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:07:37.667062Z",
     "start_time": "2024-10-25T00:07:37.634753Z"
    }
   },
   "id": "7e409b8902d59454"
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.22474487 -1.22474487 -1.22474487]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 1.22474487  1.22474487  1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example matrix\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Z-score standardization\n",
    "standardized_matrix = (matrix - np.mean(matrix, axis=0)) / np.std(matrix, axis=0)\n",
    "\n",
    "print(standardized_matrix)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-25T00:00:52.510176Z",
     "start_time": "2024-10-25T00:00:52.502537Z"
    }
   },
   "id": "98ada6744da8a867"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8be3333c41c28b82"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
